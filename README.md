# odin
A repository for independent code written, notes and related documents for fun or experiments.

## Important Tutorials/References

| Title | Description | Link |
| ----- | ----------- | ---- |
| Subplots | Working with and around subplots in matplotlib | https://matplotlib.org/3.1.0/gallery/subplots_axes_and_figures/subplots_demo.html |
| Optimisation Algorithms|https://ruder.io/optimizing-gradient-descent |
| Loss functions | |
| Git | https://itnext.io/become-a-git-pro-in-just-one-blog-a-thorough-guide-to-git-architecture-and-command-line-interface-93fbe9bdb395 |

## To do tasks

| Task |  
| ---- |
|Work on visualisations for one complete weekend|
|Reading about different optimisation algorithms and coding them out | 
|Going through the git blog tutorial |


## Completed tasks

| Task | Document |
| ----- | -------- | 

## Gone Through

| What | Description | Notes available| Resource Link | 
| ------- | ------- | ------- | ------ |
|Autograd | | | | 
|Backpropagation through time | An explanation on backpropagation through time | | http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/ | 
| Rebasing forked repo to original repo | https://digitaldrummerj.me/git-syncing-fork-with-original-repo/|

## To read 

| What | Link |
| ------- | ------- |
|Machine Learning Fairness | https://developers.google.com/machine-learning/fairness-overview/ |
|Mixed Precision Training (Tensorflow, Medium) | https://medium.com/tensorflow/automatic-mixed-precision-in-tensorflow-for-faster-ai-training-on-nvidia-gpus-6033234b2540 | 
|Self-training with Noisy Student improves ImageNet classification | https://arxiv.org/abs/1911.04252 |
|An Incremental Approach to Compiler Construction|http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf |
|Probabilistic Programming Language|-|
|A visual proof that neural nets can compute any function|http://neuralnetworksanddeeplearning.com/chap4.html | 
|Optimisation algorithms|https://ruder.io/optimizing-gradient-descent|
