{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WideResnet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUjZrvm523Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6T3oKdIEYJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "63d73b55-34b0-4984-86b1-d0458a546826"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsR7QBI5ELtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cutout(object):\n",
        "    \"\"\"Randomly mask out one or more patches from an image.\n",
        "\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "\n",
        "        return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N055Xli83Zcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                               padding=0, bias=False) or None\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(int(nb_layers)):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
        "        super(WideResNet, self).__init__()\n",
        "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
        "        assert((depth - 4) % 6 == 0)\n",
        "        n = (depth - 4) / 6\n",
        "        block = BasicBlock\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
        "        self.nChannels = nChannels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FZAxVNzGzit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3faaeZDl3kP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([])\n",
        "train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "train_transform.transforms.append(transforms.ToTensor())\n",
        "train_transform.transforms.append(normalize)\n",
        "train_transform.transforms.append(Cutout(n_holes=1, length=16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEqkzr7XHfF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYiZr8dz39Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13f9ad1c-7a76-4d81-8e99-35047adf4ef4"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR100(root='./data',train=True,download=True,transform=train_transform)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/169001437 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "169009152it [00:02, 72667009.63it/s]                               \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYzg4ZCm3_i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True,num_workers=2,pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h7o5Daz4OuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de897468-a509-4159-f8d5-3b26b9dab012"
      },
      "source": [
        "testset = torchvision.datasets.CIFAR100(root='./data',train=False,download=True,transform = test_transform)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8NUuoui4RCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testLoader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False,num_workers=2,pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzmZmfq-4TS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = tuple(trainset.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iny-W6WZ4VyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = WideResNet(28,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgahOR--4eAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "cnn = cnn.cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "cnn_optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1,\n",
        "                                momentum=0.9, nesterov=True, weight_decay=5e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLu5Y9GFJg_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = MultiStepLR(cnn_optimizer, milestones=[60, 120, 160], gamma=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUSPIncaJ9ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loader):\n",
        "    cnn.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    for images, labels in loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = cnn(images)\n",
        "\n",
        "        pred = torch.max(pred.data, 1)[1]\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "    val_acc = correct / total\n",
        "    cnn.train()\n",
        "    return val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wNULCwpKFIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "04d3f86d-2390-4a6a-b0e0-bf687fcfde03"
      },
      "source": [
        "for epoch in range(20):\n",
        "\n",
        "    xentropy_loss_avg = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    progress_bar = tqdm(trainLoader)\n",
        "    for i, (images, labels) in enumerate(progress_bar):\n",
        "        progress_bar.set_description('Epoch ' + str(epoch))\n",
        "\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        cnn.zero_grad()\n",
        "        pred = cnn(images)\n",
        "\n",
        "        xentropy_loss = criterion(pred, labels)\n",
        "        xentropy_loss.backward()\n",
        "        cnn_optimizer.step()\n",
        "\n",
        "        xentropy_loss_avg += xentropy_loss.item()\n",
        "\n",
        "        # Calculate running average of accuracy\n",
        "        pred = torch.max(pred.data, 1)[1]\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels.data).sum().item()\n",
        "        accuracy = correct / total\n",
        "\n",
        "        progress_bar.set_postfix(\n",
        "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
        "            acc='%.3f' % accuracy)\n",
        "\n",
        "    test_acc = test(testLoader)\n",
        "    tqdm.write('test_acc: %.3f' % (test_acc))\n",
        "\n",
        "    scheduler.step(epoch)\n",
        "\n",
        "torch.save(cnn.state_dict(), 'checkpoints/' + test_id + '.pt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 391/391 [00:42<00:00,  9.23it/s, acc=0.138, xentropy=3.574]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 391/391 [00:42<00:00,  9.24it/s, acc=0.195, xentropy=3.255]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2:  77%|███████▋  | 300/391 [00:32<00:09,  9.20it/s, acc=0.245, xentropy=2.995]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sQLtwLK5j7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "07cccbe5-078a-49c9-b4f1-49a3c152fce6"
      },
      "source": [
        "for epoch in range(50,60):\n",
        "  running_loss = 0  \n",
        "\n",
        "  for i,data in enumerate(trainLoader,0):\n",
        "    inputs,labels = data\n",
        "\n",
        "    cnn_optimizer.zero_grad()\n",
        "\n",
        "    outputs = cnn(inputs.cuda())\n",
        "\n",
        "    loss = criterion(outputs,labels.cuda())\n",
        "    loss.backward()\n",
        "    cnn_optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i%782==781:\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 782))\n",
        "\n",
        "print(\"Training elapsed\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[51,   782] loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-64644e6510d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m782\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m781\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       print('[%d, %5d] loss: %.3f' %\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d8lEjuZ5-Xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbb1d26f-7d91-4073-fd5b-57bd7278a2a5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testLoader:\n",
        "        images, labels = data\n",
        "        outputs = cnn(images.cuda())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.cuda()).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 1 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-4CkSCoBfuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "40eb4c75-e250-4e28-e6bd-30c5cca41d90"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r169009152it [00:30, 16337911.55it/s]                               "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG76TRMeeIRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/model2.pt\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O5sZrOKeswL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(cnn.cuda().state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bXM43_vexG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOfE1G16-i6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "90c1d94d-4e89-4699-eaea-a4bff314dce3"
      },
      "source": [
        "cnn.eval()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b064b2eb2ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ8du3oC-mpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}